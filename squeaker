#!/usr/bin/env python3
#
# Copyright 2021 Tony Garnock-Jones <tonyg@leastfixedpoint.com>
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

from pathlib import Path
from urllib.request import Request, urlopen
import argparse
import datetime
import glob
import hashlib
import json
import math
import os
import shutil
import subprocess
import sys
import tempfile
import time
import zipfile

import logging

def ensuredir(*pieces):
    p = os.path.join(*pieces)
    Path(p).mkdir(parents=True, exist_ok=True)
    return p

def cachedir():
    base = os.environ.get('XDG_CACHE_HOME', os.path.join(Path.home(), '.cache'))
    return os.path.join(base, 'squeaker')

def ensurecachedir(*pieces):
    return ensuredir(cachedir(), *pieces)

def digest(s):
    return hashlib.sha512(s.encode('utf-8')).hexdigest()

def digest_file(path):
    d = hashlib.sha512()
    with open(path, 'rb') as f:
        while True:
            buf = f.read(524288)
            if not buf:
                return d.hexdigest()
            d.update(buf)

def digest_digests(digests):
    d = hashlib.sha512()
    for item in digests:
        d.update(bytearray.fromhex(item))
    return d.hexdigest()

def digest_stage(stage_type, stage_key):
    return digest(f'{stage_type}\n{stage_key}')

def copy_with_progress(expected_str, from_fh, to_fh, extra=''):
    expected = int(expected_str) if expected_str is not None else None
    block_size = math.ceil(expected / 100) if expected is not None else 131072
    total = 0
    def status():
        return f'  {total}/{expected} ({math.floor(100.0 * (total/expected)) if expected is not None else "?"}%){extra}'
    while True:
        logging.info('\r' + status())
        buf = from_fh.read(block_size)
        if not buf:
            break
        total = total + len(buf)
        to_fh.write(buf)
    logging.info('\r' + status() + '\n')

def stage_path(stage_digest):
    return os.path.join(ensurecachedir('stages'), stage_digest)

def load_stage(stage_digest, no_cache=[]):
    infopath = stage_path(stage_digest)
    logging.debug(f'stage cache check {infopath}')
    if os.path.exists(infopath):
        with open(infopath, 'rt') as f:
            info = json.load(f)
        if info['stage_type'] in no_cache:
            logging.info(f'Ignoring (and replacing) cache entry for stage {stage_digest[:20]}')
        else:
            logging.debug(f'  cache hit')
            return info
    else:
        logging.debug(f'  cache miss')
    return None

def image_path(image_digest):
    return os.path.join(ensurecachedir('images'), image_digest)

def stage_lookup(no_cache, stage_type, stage_key_fn, if_absent, extra_fn):
    logging.debug(f'stage_lookup of type {repr(stage_type)}')
    info = load_stage(digest_stage(stage_type, stage_key_fn()), no_cache)
    if info is not None:
        return info

    with tempfile.NamedTemporaryFile(prefix='squeaker-stage-') as output:
        image_digest = if_absent(output)
        if image_digest is None:
            output.flush()
            image_digest = digest_file(output.name)
            shutil.copyfile(output.name, image_path(image_digest))

    final_stage_key = stage_key_fn()
    final_stage_digest = digest_stage(stage_type, final_stage_key)

    info = {
        'image_digest': image_digest,
        'stage_digest': final_stage_digest,
        'stage_type': stage_type,
        'stage_key': final_stage_key,
    }
    for (k, v) in extra_fn().items():
        info[k] = v

    with open(stage_path(final_stage_digest), 'wt') as f:
        json.dump(info, f, indent=2)

    return info

def download(no_cache, url):
    def if_absent(output):
        req = Request(url)
        if req.type == 'file':
            path = req.selector
            with open(path, 'rb') as from_fh:
                logging.info(f'Copying local file {repr(path)} into cache')
                copy_with_progress(expected_str=str(os.path.getsize(path)), from_fh=from_fh, to_fh=output, extra=' ' + path)
        else:
            resp = urlopen(req)
            if resp.status >= 200 and resp.status <= 299:
                logging.info(f'Downloading {url}')
                copy_with_progress(expected_str=resp.headers['content-length'], from_fh=resp, to_fh=output, extra=' ' + url)
            else:
                raise Exception(f'Could not retrieve {url}: HTTP response code {resp.status}:\n{resp.headers}')
    return stage_lookup(no_cache, 'url', lambda: url, if_absent, lambda: {
        'url': url
    })

def tag_path(tag):
    return os.path.join(ensurecachedir('tags'), tag)

def load_tag(tag, missing_ok=False):
    path = tag_path(tag)
    if os.path.exists(path):
        with open(path, 'rt') as f:
            return json.load(f)
    if missing_ok:
        return None
    raise Exception(f'Could not load tag {repr(tag)}')

def unambiguous_prefix(p):
    if os.path.exists(p):
        return p
    matches = glob.glob(p + '*')
    if len(matches) > 1:
        raise Exception(f'Ambiguous filename prefix ({len(matches)} candidates found): {p}')
    if len(matches) == 1:
        return matches[0]
    return None

def resolve_snapshot_name(image):
    info = load_tag(image, missing_ok=True)
    if info is None:
        path = unambiguous_prefix(image_path(image))
        if path is not None:
            info = {'image_digest': os.path.basename(path)}
    if info is None:
        raise Exception(f'Could not resolve tag or image {repr(image)}')
    return info

def pretty_stage(stage):
    return stage['image_digest'][:20]

def write_tag(stage, tag, extra):
    logging.info(f'Tagging {pretty_stage(stage)} as {repr(tag)}')
    info = {
        'stage_digest': stage['stage_digest'],
        'image_digest': stage['image_digest'],
        'tag': tag,
    }
    for (k, v) in extra.items():
        info[k] = v
    with open(tag_path(tag), 'wt') as f:
        json.dump(info, f, indent=2)

def extract_with_progress(z, entryname, targetname):
    if os.path.exists(targetname):
        logging.warning(f'{targetname} exists, not overwriting')
        return
    info = z.getinfo(entryname)
    with z.open(entryname, 'r') as from_fh:
        with open(targetname, 'wb') as to_fh:
            copy_with_progress(str(info.file_size), from_fh=from_fh, to_fh=to_fh, extra=' extracting: ' + entryname)

def archive_with_progress(z, sourcename, entryname):
    with open(sourcename, 'rb') as from_fh:
        with z.open(entryname, 'w') as to_fh:
            copy_with_progress(str(os.path.getsize(sourcename)), from_fh=from_fh, to_fh=to_fh, extra=' archiving: ' + entryname)

def unlink_missing_ok(path):
    try:
        os.unlink(path)
    except FileNotFoundError:
        pass

def ensure_image_present(info, build_args):
    path = image_path(info['image_digest'])
    if os.path.exists(path):
        logging.debug(f'Image exists for stage {info.get("stage_digest", "???")[:20]} at {path}')
        return info

    if build_args is None:
        raise Exception(f'Cannot find image {repr(path)}')

    logging.info(f'Rebuilding image for stage {info["stage_digest"][:20]}')

    unlink_missing_ok(stage_path(info['stage_digest']))

    desired_stage_type = info['stage_type']
    if desired_stage_type == 'url':
        return download(build_args.no_cache, info['url'])
    elif desired_stage_type == 'stage':
        parent_info = load_stage(info['parent'])
        if parent_info is None:
            raise Exception(f'Cannot find stage {info["parent"][:20]}')
        return apply_chunk(build_args, parent_info, info['chunk'])
    elif desired_stage_type == 'resource':
        parent_info = load_stage(info['parent'])
        if parent_info is None:
            raise Exception(f'Cannot find stage {info["parent"][:20]}')
        return depend_on_resource(build_args, parent_info, info['resource_path'])
    else:
        raise Exception(f'Unknown stage_type {desired_stage_type}')

def prepare_base(info, build_args):
    info = ensure_image_present(info, build_args)
    path = image_path(info['image_digest'])
    z = zipfile.ZipFile(path)
    names = z.namelist()
    imagename = next((n for n in names if n.endswith('.image')), None)
    if imagename is None:
        raise Exception(f'Base image zip file does not include any *.image files')
    changesname = imagename[:-6] + '.changes'
    if changesname not in names:
        raise Exception(f'Base image zip file contains image {repr(imagename)} but not {repr(changesname)}')
    extract_with_progress(z, imagename, 'squeak.image')
    extract_with_progress(z, changesname, 'squeak.changes')
    return info

def report_time(label, action):
    start_time = time.monotonic()
    result = action()
    end_time = time.monotonic()
    logging.info(f'    {label}: {round(end_time - start_time, 3)} seconds')
    return result

def escape_str(chunk):
    return "'" + chunk.replace("!", "!!").replace("'", "''") + "'"

def incorporate_chunk(args, chunk):
    script_body = f'''
[
    | oldRedirect buildDir logAndQuit |
    buildDir := FileStream detectFile: [FileStream readOnlyFileNamed: 'squeakerDirectory'] do: [:f | f upToEnd].
    FileDirectory setDefaultDirectory: buildDir.
    oldRedirect := TranscriptStream redirectToStdOut.
    TranscriptStream redirectToStdOut: true.
    logAndQuit := [:exn |
        FileStream stderr nextPut: Character cr.
        exn printVerboseOn: FileStream stderr.
        FileStream stderr flush.
        Smalltalk snapshot: false andQuitWithExitCode: 1].
    [
        (
            [
                [
                    Compiler evaluate: {escape_str('['+chunk+']')}
                ] on: SyntaxErrorNotification do: logAndQuit
            ] on: UndeclaredVariableWarning do: [:w |
                w defaultAction.
                Smalltalk snapshot: false andQuitWithExitCode: 1
            ]
        ) value
    ] on: UnhandledError do: [:exn | logAndQuit value: exn exception].
    Transcript flush.
    TranscriptStream redirectToStdOut: oldRedirect.
    Smalltalk garbageCollect; snapshot: true andQuit: true.
] forkAt: Processor lowestPriority + 1 "plus one to avoid having the idle process starve us".
'''
    with open('squeakerDirectory', 'wt') as squeakerDirectory:
        squeakerDirectory.write(args.directory)
    with tempfile.NamedTemporaryFile(prefix='chunk-', suffix='.st') as script:
        script.write(script_body.encode('utf-8'))
        script.flush()
        c = subprocess.run(
            [args.vm, *([args.vm_headless_flag] if args.headless else []), 'squeak.image', script.name],
            check=True)

def make_archive(output):
    with zipfile.ZipFile(output, mode='w', compression=zipfile.ZIP_DEFLATED) as z:
        archive_with_progress(z, 'squeak.image', 'squeak.image')
        archive_with_progress(z, 'squeak.changes', 'squeak.changes')

def apply_chunk(args, base_stage, chunk):
    #
    # NOTE: base_stage[0] is *UPDATED* when if_absent is called!
    #       This makes digest_inputs_fn() yield a different answer,
    #       which in turn allows us to repair a partially-cached stage-path.
    #
    base_stage = [base_stage]

    vm_digest = digest(args.vm)
    chunk_digest = digest(chunk)
    digest_inputs_fn = lambda: [base_stage[0]['stage_digest'],
                                base_stage[0]['image_digest'],
                                vm_digest,
                                chunk_digest]
    was_cached = [True]
    def if_absent(output):
        was_cached[0] = False
        with tempfile.TemporaryDirectory(prefix='squeaker-build-') as builddirname:
            os.chdir(builddirname)
            base_stage[0] = prepare_base(base_stage[0], build_args=args)
            logging.info(f' --- {pretty_stage(base_stage[0])}')
            logging.info(('Running:\n' + chunk.replace('\r', '\n')).replace('\n', '\n    '))
            report_time('execution', lambda: incorporate_chunk(args, chunk))
            report_time('archiving', lambda: make_archive(output))
            os.chdir(args.directory)
    info = stage_lookup(args.no_cache, 'stage', lambda: digest_digests(digest_inputs_fn()), if_absent, lambda: {
        'parent': base_stage[0]['stage_digest'],
        'digest_inputs': digest_inputs_fn(),
        'vm': args.vm,
        'chunk': chunk,
    })
    if was_cached and args.verbose > 0:
        logging.info(f' >>> image {pretty_stage(info)}, stage {info["stage_digest"][:20]}')
        logging.info(('     is the cached result of command(s):\n' + chunk.replace('\r', '\n')).replace('\n', '\n    '))
    return info

def depend_on_resource(args, base_stage, resource_path):
    #
    # NOTE: base_stage[0] is *UPDATED* when if_absent is called!
    #       This makes digest_inputs_fn() yield a different answer,
    #       which in turn allows us to repair a partially-cached stage-path.
    #
    base_stage = [base_stage]

    if os.path.exists(resource_path):
        resource_digest = digest_file(resource_path)
    else:
        resource_digest = None

    digest_inputs_fn = lambda: [base_stage[0]['stage_digest'],
                                base_stage[0]['image_digest'],
                                *([resource_digest] if resource_digest else [])]

    was_cached = [True]
    def if_absent(output):
        was_cached[0] = False
        base_stage[0] = ensure_image_present(base_stage[0], args)
        logging.info(f' --- {pretty_stage(base_stage[0])}')
        logging.info(f'Resource digest {resource_digest[:20] if resource_digest else "(absent)"} for {resource_path}')
        return base_stage[0]['image_digest']
    def mk_extra():
        extra = {
            'parent': base_stage[0]['stage_digest'],
            'digest_inputs': digest_inputs_fn(),
            'resource_path': resource_path,
        }
        if resource_digest:
            extra['resource_digest'] = resource_digest
        return extra
    info = stage_lookup(args.no_cache, 'resource', lambda: digest_digests(digest_inputs_fn()), if_absent, mk_extra)
    if was_cached and args.verbose > 0:
        logging.info(f' >>> image {pretty_stage(info)}, stage {info["stage_digest"][:20]}')
        logging.info(f'     is the cached result of depending on resource {resource_path}')
    return info

class ChunkReader:
    def __init__(self, fh):
        self.fh = fh
        self.buf = None

    def peek(self):
        if self.buf is None:
            self.buf = self.fh.read(1)
        return self.buf

    def drop(self):
        self.buf = None

    def __iter__(self):
        return self

    def __next__(self):
        chunk = b''
        while self.peek() != b'':
            if self.peek() == b'!':
                self.drop()
                if self.peek() == b'!':
                    self.drop()
                    chunk = chunk + b'!'
                else:
                    return chunk.decode('utf-8')
            else:
                chunk = chunk + self.peek()
                self.drop()
        if chunk == b'':
            raise StopIteration
        else:
            return chunk.decode('utf-8')

def lex_string_literal(s):
    if not (s[0] == "'" and s[-1] == "'"):
        return None
    s = s[1:-1]
    s = s.replace("''", "'")
    return s

def lex_symbol(s):
    if s[0] != '#':
        return None
    return lex_string_literal(s[1:])

def command_build(args):
    args.directory = os.path.abspath(args.directory)
    os.chdir(args.directory)

    base_stage = None

    with open(args.f, 'rb') as squeakerfile:
        for chunk in ChunkReader(squeakerfile):
            chunk = chunk.strip()

            if chunk.startswith('from:'):
                loc = chunk[5:].strip()

                lit = lex_string_literal(loc)
                if lit is not None:
                    base_stage = download(args.no_cache, lit)
                    continue

                srctag = lex_symbol(loc)
                if srctag is not None:
                    base_stage = load_tag(srctag)
                    continue

                raise Exception('Cannot resolve "from:" specifier: ', repr(loc))
            elif chunk.startswith('resource:'):
                resource_path = lex_string_literal(chunk[9:].strip())
                if resource_path is not None:
                    base_stage = depend_on_resource(args, base_stage, resource_path)
                    continue
                raise Exception('Invalid "resource:" chunk: ', repr(chunk))
            elif chunk.startswith('fileIn:'):
                literal_path = chunk[7:].strip()
                resource_path = lex_string_literal(literal_path)
                if resource_path is not None:
                    base_stage = depend_on_resource(args, base_stage, resource_path)
                    if not os.path.exists(resource_path):
                        raise Exception('Missing file in fileIn: ' + resource_path)
                    base_stage = apply_chunk(args, base_stage, f'Installer installFile: {literal_path}')
                    continue
                raise Exception('Invalid "fileIn:" chunk: ', repr(chunk))
            elif chunk == '':
                pass
            else:
                if base_stage is None:
                    raise Exception('No "from:" specifier given')
                base_stage = apply_chunk(args, base_stage, chunk)

    if base_stage is not None:
        base_stage = ensure_image_present(base_stage, build_args=args)
        if args.t:
            write_tag(base_stage, args.t, {})
        print(base_stage['image_digest'])

def prune_recent_changes():
    changesdir = ensurecachedir('recentchanges')
    changesfiles = os.listdir(changesdir)
    changesfiles = sorted(changesfiles)
    for filename in changesfiles[:-5]:
        unlink_missing_ok(os.path.join(changesdir, filename))

def utcstamp():
    # utcnow() is deprecated and scheduled to be removed in some future python
    # see https://discuss.python.org/t/deprecating-utcnow-and-utcfromtimestamp/26221/5
    #
    # return datetime.datetime.utcnow().isoformat(timespec='seconds') + 'Z'
    #
    d = datetime.datetime.now(datetime.timezone.utc).replace(tzinfo=None)
    return d.isoformat(timespec='seconds') + 'Z'

def command_run(args):
    info = resolve_snapshot_name(args.image)
    old_cwd = os.getcwd()
    with tempfile.TemporaryDirectory(prefix='squeaker-run-') as rundirname:
        try:
            os.chdir(rundirname)
            logging.info(f'Image: {info["image_digest"]}')
            prepare_base(info, build_args=None)
            subprocess.run(
                [ *(['sudo', '--'] if args.root else []),
                  args.vm,
                  *([args.vm_headless_flag] if args.headless else []),
                  'squeak.image',
                  *args.args],
                check=True)
        finally:
            try:
                n = 'squeak.' + utcstamp() + '.changes'
                shutil.move('squeak.changes', os.path.join(ensurecachedir('recentchanges'), n))
                prune_recent_changes()
            finally:
                os.chdir(old_cwd)

def all_blobs(dirname):
    blobs = []
    for filename in os.listdir(dirname):
        with open(os.path.join(dirname, filename), 'rt') as f:
            blobs.append(json.load(f))
    return blobs

def command_gc(args):
    root_images = set()
    marked_images = set()
    marked_stages = set()

    image_info = {}
    stage_info = {}

    for info in all_blobs(ensurecachedir('stages')):
        image_info.setdefault(info['image_digest'], []).append(info)
        stage_info[info['stage_digest']] = info

    def mark_stage(stage_digest, depth):
        marked_stages.add(stage_digest)
        info = stage_info.get(stage_digest, None)
        if info is None:
            # TODO: fsck-style warnings here
            return
        if depth <= args.keep_intermediate_stages:
            marked_images.add(info['image_digest'])
        if 'parent' in info:
            mark_stage(info['parent'], depth + 1)

    for info in all_blobs(ensurecachedir('tags')):
        marked_images.add(info['image_digest'])
        mark_stage(info['stage_digest'], 0)

    if args.delete_urls is False:
        for info in stage_info.values():
            if info['stage_type'] == 'url':
                mark_stage(info['stage_digest'], 0)
    elif args.delete_urls is True:
        for info in stage_info.values():
            if info['stage_type'] == 'url':
                if info['stage_digest'] in marked_stages:
                    marked_images.add(info['image_digest'])
    elif args.delete_urls == 'all':
        for info in stage_info.values():
            if info['stage_type'] == 'url':
                marked_images.discard(info['image_digest'])
    else:
        raise Exception(f'Invalid delete_urls setting: {repr(args.delete_urls)}')

    all_images = set(os.listdir(ensurecachedir('images')))
    all_stages = set(os.listdir(ensurecachedir('stages')))

    doomed_images = all_images - marked_images
    doomed_stages = all_stages - marked_stages

    logging.info(('Would remove' if args.dry_run else 'Removing') + \
                 f' {len(doomed_images)} image(s) and {len(doomed_stages)} stage(s)')

    for i in doomed_images:
        logging.info(f'    image {i}')
        if not args.dry_run:
            os.unlink(os.path.join(ensurecachedir('images'), i))
    for s in doomed_stages:
        logging.info(f'    stage {s}')
        if not args.dry_run:
            os.unlink(os.path.join(ensurecachedir('stages'), s))

def command_tags(args):
    for info in all_blobs(ensurecachedir('tags')):
        print(info['tag'])

def command_resolve_tag(args):
    print(load_tag(args.tag)['image_digest'])

def command_dot(args):
    print('digraph G {')
    for info in all_blobs(ensurecachedir('tags')):
        tn = f'"tag_{info["tag"]}"'
        print(f'  {tn} [shape=octagon, style=filled, fillcolor="#ffccff"];')
        print(f'  image_{info["image_digest"][:8]} -> {tn};')
    stages = dict((s['stage_digest'], s) for s in all_blobs(ensurecachedir('stages')))
    for info in stages.values():
        print(f'  stage_{info["stage_digest"][:8]} [shape=note, style=filled, fillcolor="#ffcccc"];')
        print(f'  image_{info["image_digest"][:8]} [shape=ellipse, style=filled, fillcolor="#ccffcc"];')
        print(f'  stage_{info["stage_digest"][:8]} -> image_{info["image_digest"][:8]};')
        ty = info['stage_type']
        if ty == 'url':
            un = f'url_{info["image_digest"][:8]}'
            url_label = dotescape(info["url"] + '\n' + info["image_digest"][:20])
            print(f'  {un} [shape=box, style=filled, fillcolor="#ccccff", label={url_label}];')
            print(f'  {un} -> stage_{info["stage_digest"][:8]};')
        elif ty == 'stage':
            print(f'  note_{info["stage_digest"][:8]} [shape=note, style=filled, fillcolor="#ffffaa", label={dotescape(info["chunk"])}];')
            print(f'  note_{info["stage_digest"][:8]} -> stage_{info["stage_digest"][:8]};')
            print(f'  image_{stages[info["parent"]]["image_digest"][:8]} -> stage_{info["stage_digest"][:8]};')
            print(f'  stage_{info["parent"][:8]} -> stage_{info["stage_digest"][:8]};')
        elif ty == 'resource':
            r_label = dotescape(info["resource_path"] + '\n' + info.get("resource_digest", "(absent)")[:20])
            print(f'  note_{info["stage_digest"][:8]} [shape=box, style=filled, fillcolor="#ccccff", label={r_label}];')
            print(f'  note_{info["stage_digest"][:8]} -> stage_{info["stage_digest"][:8]};')
            par = stages.get(info["parent"])
            if par is None:
                par_img = f'image_UNKNOWN_from_stage_{info["parent"][:8]}'
            else:
                par_img = par["image_digest"][:8]
            print(f'  image_{par_img} -> stage_{info["stage_digest"][:8]};')
            print(f'  stage_{info["parent"][:8]} -> stage_{info["stage_digest"][:8]};')
        else:
            pass
    print('}')

def dotescape(s):
    s = s.replace('\\', '\\\\')
    s = s.replace('\n', '\\l')
    s = s.replace('\r', '\\l')
    s = s.replace('"', '\\"')
    return f'"{s}\\l"'

def command_create(args):
    args.targetdirectory = os.path.abspath(args.targetdirectory)
    info = resolve_snapshot_name(args.image)
    old_cwd = os.getcwd()
    try:
        os.chdir(ensuredir(args.targetdirectory))
        logging.info(f'Creating image from {args.image} in {args.targetdirectory}')
        prepare_base(info, build_args=None)
    finally:
        os.chdir(old_cwd)

def command_untag(args):
    for tag in args.tag:
        unlink_missing_ok(tag_path(tag))

def command_unstage(args):
    for digestprefix in args.digest:
        path = unambiguous_prefix(stage_path(digestprefix))
        if path is not None:
            print(os.path.basename(path))
            unlink_missing_ok(path)

def command_print_autodetect(args):
    print(f'vm-headless-flag\t{args.vm_headless_flag}')
    print(f'vm\t{args.vm if hasattr(args, 'vm') else discover_vm()}')

class CustomHandler(logging.StreamHandler):
    def emit(self, record):
        if record.msg[0] == '\r':
            record.msg = record.msg[1:]
            self.stream.write('\r')
            if record.msg[-1] == '\n':
                self.terminator = '\n'
                record.msg = record.msg[:-1]
            else:
                self.terminator = ''
        else:
            if self.terminator == '':
                self.stream.write('\n')
            self.terminator = '\n'
        return super().emit(record)

def discover_vm():
    DEFAULT='squeak'
    try:
        if sys.platform == 'darwin':
            apps = sorted([n for n in os.listdir('/Applications')
                           if 'squeak' in n.lower() and n.endswith('.app')])
            return '/Applications/' + apps[-1] + '/Contents/MacOS/Squeak'
        else:
            return DEFAULT
    except:
        return DEFAULT

def discover_headless_flag():
    DEFAULT='-vm-display-null'
    try:
        if sys.platform == 'darwin':
            return '-headless'
        else:
            return DEFAULT
    except:
        return DEFAULT

def main(argv):
    app_name = os.path.basename(argv[0])
    argv = argv[1:]

    parser = argparse.ArgumentParser(prog=app_name)
    parser.add_argument('-d', '--debug', action='store_true', default=False,
                        help='Enable debug logging')
    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help='Increment verbosity level')
    parser.add_argument('--vm-headless-flag', type=str, default=discover_headless_flag(),
                        help=argparse.SUPPRESS)
    parser.set_defaults(handler=lambda args: parser.print_help())
    sp = parser.add_subparsers()

    p = sp.add_parser('build', help='Build image')
    p.add_argument('-f', metavar='Squeakerfile.st', type=str, default='Squeakerfile.st',
                   help='Specify Squeakerfile to use in <directory>')
    p.add_argument('-t', metavar='tag', type=str, default=None,
                   help='Optionally tag the produced image with this name')
    p.add_argument('--no-cache-urls', dest='no_cache', action='append_const', const='url',
                   help='Always redownload from URLs')
    p.add_argument('--no-cache-stages', dest='no_cache', action='append_const', const='stage',
                   help='Always recompute build stages')
    p.add_argument('--headless', action='store_true', default=True,
                   help='Run squeak with a dummy display, not showing the window')
    p.add_argument('--no-headless', dest='headless', action='store_false',
                   help='Run squeak in graphical mode, showing the window')
    p.add_argument('--vm', type=str, default=discover_vm(),
                   help='Specify VM executable name')
    p.add_argument('directory', type=str,
                   help='Directory to build the image in')
    p.set_defaults(no_cache=[], handler=command_build)

    p = sp.add_parser('run', help='Run image')
    p.add_argument('--vm', type=str, default=discover_vm(),
                   help='Specify VM executable name')
    p.add_argument('--root', action='store_true', default=False,
                   help='Execute VM within `sudo`')
    p.add_argument('--headless', action='store_true', default=False,
                   help='Run squeak with a dummy display, not showing the window')
    p.add_argument('--no-headless', dest='headless', action='store_false',
                   help='Run squeak in graphical mode, showing the window')
    p.add_argument('image')
    p.add_argument('args', nargs=argparse.REMAINDER)
    p.set_defaults(handler=command_run)

    p = sp.add_parser('gc', help='Garbage-collect images, stages etc.')
    p.add_argument('-n', '--dry-run', dest='dry_run', action='store_true', default=False,
                   help='Show what would be garbage-collected without deleting anything')
    p.add_argument('--delete-unreferenced-urls', dest='delete_urls', action='store_true', default=False,
                   help='Delete unreferenced downloaded image files')
    p.add_argument('--delete-all-urls', dest='delete_urls', action='store_const', const='all',
                   help='Delete all downloaded image files')
    p.add_argument('--discard-all-intermediate', dest='keep_intermediate_stages', action='store_const', const=0, default=math.inf,
                   help='Discard all intermediate stage images')
    p.add_argument('--keep-intermediate', metavar='N', dest='keep_intermediate_stages', type=int,
                   help='Keep most-recent N intermediate stage images for each tag')
    p.set_defaults(handler=command_gc)

    p = sp.add_parser('tags', help='List available tagged images')
    p.set_defaults(handler=command_tags)

    p = sp.add_parser('resolve-tag', help='Resolve a tagged image to an on-disk path')
    p.add_argument('tag')
    p.set_defaults(handler=command_resolve_tag)

    p = sp.add_parser('dot', help='Produce graphviz dot description of objects')
    p.set_defaults(handler=command_dot)

    p = sp.add_parser('create', help='Create a permanent image from a tag or image digest')
    p.add_argument('image')
    p.add_argument('targetdirectory')
    p.set_defaults(handler=command_create)

    p = sp.add_parser('untag', help='Remove tags')
    p.add_argument('tag', nargs='*')
    p.set_defaults(handler=command_untag)

    p = sp.add_parser('unstage', help='Remove cached stages')
    p.add_argument('digest', nargs='*')
    p.set_defaults(handler=command_unstage)

    p = sp.add_parser('print-autodetect', help='Show autodetected settings')
    p.set_defaults(handler=command_print_autodetect)

    args = parser.parse_args(argv)
    logging.basicConfig(level=logging.DEBUG if args.debug else logging.INFO,
                        handlers=[CustomHandler()])
    try:
        args.handler(args)
    except Exception as e:
        logging.error(str(e), exc_info=e if args.debug else False)
        sys.exit(1)

if __name__=='__main__':
    main(sys.argv)
